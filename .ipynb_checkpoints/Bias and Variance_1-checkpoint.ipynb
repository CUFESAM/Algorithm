{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias-Variance分解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、基本原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假定的真实模型为$$ y = f(x) + \\epsilon ,$$其中$E(\\epsilon)=0,V(\\epsilon)={\\sigma}^{2}.$\n",
    "\n",
    "\n",
    "对给定训练集$\\{(x_{i},y_{i})\\}$下训练出的假设$h(x)=ax+b$，我们通过预测误差$E_{P}{(y^{*}-h(x^{*}))}^{2}$对其进行评价\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、基本思路及待讨论解决问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们假定训练集样本点的概率分布满足$E_{P}[Z]=\\underline{Z}$,于是\n",
    "$$\n",
    "\\begin{split}\n",
    "& E_{P}{(y^{*}-h(x^{*}))}^{2}\\\\\n",
    "= & E[{(h(x^{*})-\\underline{h(x^{*})})}^{2}] + {[\\underline{h(x^{*})}-f(x^{*})]}^{2} +  E[{(y^{*}-f(x^{*}))}^{2}]\\\\ \n",
    "= & Variance + Bias^{2} + Noise\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "然后用足够多的训练样本点$(x_i^*,y_i^*)$去评价假设$h(x)$，对每个给定的$(x_i^*,y_i^*)$，有\n",
    "\n",
    "$$Variance_i = E[{(h(x_i^*)-\\underline{h(x_i^*)})}^{2}]$$\n",
    "\n",
    "$$Bias_i^2 = {[\\underline{h(x_i^{*})}-f(x_i^{*})]}^{2}$$\n",
    "\n",
    "于是我们可以得到对假定模型$h(x)=ax+b$最终的评价\n",
    "\n",
    "$$Bias^2 = E[E[{(h(x_i^*)-\\underline{h(x_i^*)})}^{2}]]$$\n",
    "\n",
    "$$Variance = E[{[\\underline{h(x_i^{*})}-f(x_i^{*})]}^{2}]$$\n",
    "\n",
    "\n",
    "下面我们用程序来完成这个过程，并在这个基础上讨论当误差项$\\epsilon$的方差${\\sigma}^{2}$变化时，$h(x)$复杂度的选择问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、代码部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代码思路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "真实函数$$ y = 2{e}^x + \\epsilon ,$$其中$\\epsilon\\sim N(0,\\sigma^2)$。对$f(x) = 2{e}^x$进行泰勒展开，有$$f(x) = 2{e}^x = 2x + 2x^2 + 2x^3 + ...$$\n",
    "\n",
    "于是选择不同光滑度的函数h(x)进行训练，下列公式光滑度由低到高：\n",
    " $$h(x)_1 = a_1x+b$$\n",
    " $$h(x)_2 = a_1x+a_2x^2 + b$$\n",
    " $$h(x)_3 = a_1x+a_2x^2+a_3x^3+b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代码内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自定义函数lml\n",
    "函数$lml$的输入为训练集TR与测试集TE，输出为以TR为训练集训练出的$h(x)$关于TE的预测集。\n",
    "\n",
    "\n",
    "TR和TE变量结构相同，TR为训练集，TE为测试集，第一个均为因变量\n",
    "\n",
    "\n",
    "mlm以向前法的顺序，添加自变量，建立相应的回归模型，并给出与之对应的TE的因变量的预测值\n",
    "\n",
    "\n",
    "预测结果排列为1个向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlm <- function(TR, TE){\n",
    "  vname = names(TR) \n",
    "  yn=vname[1]         #因变量名称\n",
    "  xn=vname[-1]        #自变量名称\n",
    "  mp=length(xn)       #自变量的维数\n",
    " \n",
    "  ypr=NULL\n",
    "  tm=paste(yn,xn[1],sep=\"~\")     #将因变量y和第一个自变量粘贴成y~x.1的形式，建立lm函数。\n",
    "  fam=formula(tm)                #公式化\n",
    "  cp=1\n",
    "  repeat{\n",
    "    lm1 = lm(fam,TR)             #运用公式化后的lm函数对训练集TR做回归，得到相应的回归系数。\n",
    "    ypr=c(ypr,predict(lm1,TE))   #给出与之对应的TE的因变量的预测值\n",
    "    \n",
    "    #使用向前法，依次添加自变量x.2、x.3、……、x.p，重新建立lm函数。\n",
    "    if(cp>=mp) break            \n",
    "    cp=cp+1                   \n",
    "    tm=paste(tm,xn[cp],sep=\"+\") \n",
    "    fam=formula(tm)\n",
    "  }\n",
    "  as.vector(ypr)                #返回结果为TE的因变量的预测值，其为一个拉直的向量。         \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 自定义函数BV\n",
    "计算给定光滑度和方差后得到的预测函数的偏差bias和方差variance\n",
    "\n",
    "\n",
    "有k个样本量为n的训练集dataTR，与一个样本量为N的测试集dataTE，其中p为做线性回归的自变量的最高阶数，$\\sigma$为随机误差的标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(plyr)\n",
    "BV <- function(p, sigma, N, n, k){\n",
    "\n",
    "  ##构造两个结构相同的数据集，其中自变量维数均为p，第一个均为因变量\n",
    "  #构造样本数为N的测试集dataTE\n",
    "  nx <- runif(N,-1,1) #一个样本数为N的均匀分布的随机数\n",
    "  ny <- 2*exp(nx)+rnorm(N,0,sigma)                 #真实函数为y = 2*exp(x)+epsilon 其中epsilon~N(0,sigma^2)\n",
    "  nz <- matrix(nx,N,p)                             #构造一个自变量矩阵，其中自变量维数为p,样本数为N\n",
    "  for(i in 2:p) nz[,i] <- 10*nz[,i]*nz[,i-1]      #乘10为了量纲不要差太多，因为是(0,1)间的，平方会差很多\n",
    "  dataTE <- data.frame(y=ny,z=nz)                  \n",
    "\n",
    "  #构造样本数为n*k的训练集dataTR\n",
    "  x <- runif(n * k,-1,1)\n",
    "  y <- 2 * exp(x) + rnorm(n*k,0,sigma)\n",
    "  z <- matrix(x,n*k,p)\n",
    "  for(i in 2:p) z[,i]=10*z[,i]*z[,i-1];\n",
    "  dataTR <- data.frame(y=y,z=z)\n",
    "\n",
    "  \n",
    "  index <- rep(1:k,rep(n,k)) \n",
    " \n",
    "  ##使用自定义函数mlm，对样本量为n的训练集dataTR做关于自变量x从1到p阶的线性回归\n",
    "  ##得到与之对应的关于测试集dataTE的预测。\n",
    "  ##重复k次，计算偏差和方差。\n",
    "  PRE=daply(dataTR, .(index), mlm, TE = dataTE)     #预测值，为一个k*(N*p)的矩阵\n",
    "  b =  ( apply(PRE,2,mean) - rep(2*exp(nx),p) )^2   #(E(h(x))-f(x))^2\n",
    "  b = matrix(b, nrow=N, byrow=F)                    #按列排成N*p的矩阵，第j列的对应的回归模型的自变量最高阶数为j\n",
    "  b = apply(b, 2, mean)                             #求不同阶数对应的预测函数的偏差，E[(E(h(x))-f(x))^2]\n",
    "  v =  apply(PRE, 2, var)                           #var(h(x))\n",
    "  v = matrix(v, nrow=N, byrow=F)                    #按列排成N*p的矩阵，第j列的对应的回归模型的自变量最高阶数为j\n",
    "  v = apply(v,2,mean)                               #求不同阶数对应的预测函数的方差，E[var(h(x))]                        \n",
    "  mse= b+v\n",
    "  \n",
    "  list(mse=mse, bias=b, var=v)\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型复杂度选取\n",
    "\n",
    "\n",
    "使用自定义函数，分别计算误差项方差$\\sigma^2$为$1^2、5^2和10^2$时，不同光滑度对应预测函数$h(x)$的Bias和Variance，对比不同复杂度下模型的优劣。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 3\n",
      "       msigma\n",
      "[1,] 3      1\n",
      "[2,] 3      5\n",
      "[3,] 3     10\n"
     ]
    }
   ],
   "source": [
    "#定义训练集、测试集的容量、阶数p和sigma的取值\n",
    "N=2000; k=2000; n=500\n",
    "msigma=c(1,5,10)            \n",
    "NL=length(msigma)\n",
    "ps=cbind(3,msigma)\n",
    "\n",
    "print(NL)\n",
    "print(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$mse\n",
      "[1] 0.111726282 0.009132421 0.008319986\n",
      "\n",
      "$bias\n",
      "[1] 1.069435e-01 2.922602e-03 4.958742e-05\n",
      "\n",
      "$var\n",
      "[1] 0.004782787 0.006209818 0.008270398\n",
      "\n",
      "$mse\n",
      "[1] 0.2147534 0.1588695 0.2076463\n",
      "\n",
      "$bias\n",
      "[1] 0.1088951230 0.0029341391 0.0001097702\n",
      "\n",
      "$var\n",
      "[1] 0.1058582 0.1559353 0.2075365\n",
      "\n",
      "$mse\n",
      "[1] 0.5197159 0.6182644 0.8129079\n",
      "\n",
      "$bias\n",
      "[1] 0.1021238805 0.0030756568 0.0003913956\n",
      "\n",
      "$var\n",
      "[1] 0.4175920 0.6151887 0.8125165\n",
      "\n",
      "Time difference of 1.171259 mins\n"
     ]
    }
   ],
   "source": [
    "#计算不同h(x)的bias和variance\n",
    "set.seed(1)\n",
    "timestart <- Sys.time()\n",
    "\n",
    "#每一次循环均为给定一个sigma，使用自定义函数BV计算最高阶数为p时的偏差和方差\n",
    "for(nl in 1:NL) print(BV(ps[nl,1],ps[nl,2], N, n, k))\n",
    "\n",
    "timeend <- Sys.time()\n",
    "runningtime <- timeend-timestart\n",
    "print(runningtime)                                        #计算运行时间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结论\n",
    "#### 1. 偏差Bias\n",
    "Bias度量了模型预测期望函数和真实函数的偏离程度，体现了模型的**拟合效果**。  \n",
    "\n",
    "在给定较低的噪声方差\\$sigma^2$时，偏差会随着模型复杂度的增加而减少；  \n",
    "而当噪声方差过高时，模型复杂度的增加会导致预测函数偏离真实函数，即偏差增加。\n",
    "#### 2. 方差Variance\n",
    "Variance表示不同的训练数据集训练出的差异，体现了模型的**稳定性**。  \n",
    "随着模型复杂度的增加，模型的简洁和稳定性均会下降，这体现在方差的增加上。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
